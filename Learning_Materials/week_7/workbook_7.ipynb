{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbook 7: Artificial Neural Networks 1 - Perceptrons\n",
    "\n",
    "Overview of activities and objectives of this workbook:\n",
    "\n",
    "1. The first part of this workbook will introduce the Perceptron algorithm for supervised learning, and the building blocks of artificial neural networks.\n",
    "    - We introduce the Perceptron algorithm and you are provided a code implementation for a 2 input Perceptron.\n",
    "    - We will then show Perceptrons can learn simple logical operator functions, using binary truth-table data.\n",
    "\n",
    "2. The second part of this workbook will demonstrate Perceptron decision boundaries.\n",
    "    - Perceptrons are only capable of learning linear decision boundaries.\n",
    "    - This demonstrates the limitations of Perceptrons and why we might need to combine them into networks.\n",
    "\n",
    "3. The third part of this workbook will apply the Perceptron to real valued data.\n",
    "    - We will use the Iris dataset we introduced in the previous weeks.\n",
    "    - Then demonstrate how you might apply a simple linear classifier to multi-class data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"background:black;width:100%;height:10px\"></div>\n",
    "\n",
    "# Part 1: Perceptrons - The basis of Artificial Neural Networks\n",
    "\n",
    "Perceptrons, invented by Frank Rosenblatt in the late 1950's,\n",
    "are a form of supervised machine learning algorithm inspired by neuron cells.\n",
    "In neurons, signals come in along the dendrites and out along the axon. \n",
    "A synapse is the connection between the axon of one cell and the dendrites of another.\n",
    "Crudely, input signals are 'summed' and if they reach a certain threshold the neuron 'fires'\n",
    "and sends a signal down the synapse to the connected cells.\n",
    "\n",
    "![Perceptron](figures/Perceptron.png \"Perceptron Image\")\n",
    "\n",
    "Perceptrons are an algorithmic approximation of this process and can learn to solve simple classification problems.  \n",
    "Input values are multiplied by a learnable parameter called a *weight*.  \n",
    "If the sum of the inputs $\\times$ weights is over a certain threshold the Perceptron 'fires' and generates an output.  \n",
    "We use the *error* in the output to change the value of the *weights* by a small amount - the *learning rate*.  \n",
    "The process is repeated until the error is 0, or as small as we can get it.\n",
    "\n",
    "**Note:** \n",
    "- The threshold which determines if the Perceptron produces an output is determined by its *activation function*.\n",
    "- For Perceptrons this is often a step function which outputs a 1 or 0 i.e. 'fires' or not.\n",
    "- However, it can also be a non-linear function such as sigmoid (also called `logistic`), which will always produce a real numbered output in the range 0 to 1.\n",
    "\n",
    "### Perceptron - Algorithm\n",
    "\n",
    "1. Set weights to random values in range [-0.5, 0.5]\n",
    "\n",
    "2. Set learning rate to a small value, usually less than 0.5\n",
    "\n",
    "3. For each training example in the dataset i.e one 'epoch'\n",
    "\n",
    "    A. Calculate output (activation)\n",
    "    \n",
    "    $sum = \\sum\\limits_{i=0}^{n} w_i \\times x_i$\n",
    "      \n",
    "    $if\\ sum >\\ 0 \\\\ \\;\\;\\;activation = 1 $ &nbsp;&nbsp;&nbsp; $\\\\else \\\\ \\;\\;\\;activation = 0$\n",
    "       \n",
    "    B. Calculate error\n",
    "    \n",
    "    $error = target \\, output - activation$\n",
    "\n",
    "    C. Update each of the weights values\n",
    "    \n",
    "    $change \\, in \\, weight = error \\times input \\times learning \\, rate$\n",
    "\n",
    "\n",
    "4. Repeat from step 3 until error is 0 (or as close as possible), or for the number of training epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:black;width:100%;height:3px\"></div><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"color:black\"><h2>Activity 1: Perceptrons - Logical Operators</h2>\n",
    "The following few sections create binary datasets (based on truth tables) for logical operators and then implement and train a perceptron to 'solve' the logical functions.\n",
    "\n",
    "You should try and familiarise yourself with the algorithm and how the process builds a model by learning values for the weights.\n",
    "<ol>\n",
    "    <li>Compare the pseudocode/algorithm above with the code implementation and try to understand how it learns by updating the weights.</li>\n",
    "    <li>Try changing the <code>learning_rate</code> parameter, which controls how large the change in weights is, and see how that effects learning.</li>\n",
    "    <li>Try changing the <code>target_outputs</code> to <code>target_outputs_OR</code> or <code>target_outputs_XOR</code>. For each dataset/problem:\n",
    "        <ul>\n",
    "            <li>Make a prediction about whether you will see exactly the same thing when you run the cell again.</li>\n",
    "            <li>Make a prediction about whether the perceptron will solve the problem (if not, why not?)</li>\n",
    "            <li><b>Be honest!</b>: Write down your answer, and your reasoning <i>before</i> you run the cell :)</li>\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Finally, answer the Multiple Choice Questions to check your understanding</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create the datasets - the logical *connective* functions\n",
    "\n",
    "We are going to use binary data to show that Perceptrons can learn to represent logical functions,\n",
    "though you could also think about it as a prediction/classification problem\n",
    "i.e. for a given set of inputs what is the correct output.\n",
    "A truth table can be used as the Perceptrons *training* data, with each row representing an input example.\n",
    "Each training example has two inputs (*features*) and one output (*label*).\n",
    "\n",
    "| Input 1| Input 2| AND label | OR label  | XOR label |\n",
    "|:------:|:------:|:---:|:---:|:---:|\n",
    "| 0      | 0      | 0   | 0   | 0   | \n",
    "| 0      | 1      | 0   | 1   | 1   |\n",
    "| 1      | 0      | 0   | 1   | 1   |\n",
    "| 1      | 1      | 1   | 1   | 0   |\n",
    "\n",
    "First we will import some python modules and then create the training data.\n",
    "\n",
    "**Note:** Input data is often denoted as X and labels/target outputs with Y.\n",
    "Here we are going to use **inputs**, but the target outputs have been labeled **AND**, **OR** and **XOR**.\n",
    "This is so we can be clear about what the outputs should be.\n",
    "\n",
    "**Run the cell below to create the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "\n",
    "# Create input and target output data\n",
    "inputs = [[0, 0],\n",
    "          [1, 0],\n",
    "          [0, 1],\n",
    "          [1, 1]] \n",
    "print(f\"Input data: {inputs}\" )\n",
    "\n",
    "target_outputs_AND = [0, 0, 0, 1]\n",
    "print(f\"target_outputs_AND: {target_outputs_AND}\" )\n",
    "\n",
    "target_outputs_OR = [0, 1, 1, 1]\n",
    "print(f\"target_outputs_OR: {target_outputs_OR} \")\n",
    "\n",
    "target_outputs_XOR = [0, 1, 1, 0]\n",
    "print(f\"target_outputs_XOR: {target_outputs_XOR}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2: Implementing a class for a Perceptron classifier\n",
    "\n",
    "Now lets write a function to build and train a Perceptron.\n",
    "This is just an implementation of the algorithm above, except we are going to train one **step** or one **epoch** at a time.\n",
    "This allows us to see what the algorithm is doing more clearly.\n",
    "\n",
    "- A training **step** applies the algorithm to just one input example (A, B and C above).\n",
    "- An **epoch** repeats the training step for all input examples in the data (so in this case 4).\n",
    "\n",
    "First we define the learning rate and model.  \n",
    "**Run the next cell** to define the class we used in the lectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class two_input_perceptron:\n",
    "    \"\"\" Simple implementation of perceptron with two inputs\"\"\"\n",
    "    \n",
    "    def  __init__(self, learning_rate:float=0.1):\n",
    "        \"\"\" create a perceptron initialised with random weights\"\"\"\n",
    "        self.weight1 = np.random.rand()\n",
    "        self.weight2 = np.random.rand()\n",
    "        self.bias_weight = np.random.rand()\n",
    "        self.learning_rate = learning_rate\n",
    "        print(f\"Perceptron created with initial random weights: {self.__dict__}\")\n",
    "\n",
    "\n",
    "    def fit(self, data:np.ndarray, labels:np.array, max_epochs:int=50):\n",
    "        \"\"\" fits the perceptron weights to the supplied data \"\"\"\n",
    "\n",
    "        # loop for a number of epochs\n",
    "        for epoch in range(max_epochs):\n",
    "            errors_this_epoch = 0\n",
    "\n",
    "            # go through each training example in turn\n",
    "            for example in range(len(data)):\n",
    "                \n",
    "                input1 = data[example][0]\n",
    "                input2 = data[example][1]\n",
    "                target = labels[example]\n",
    "\n",
    "                # calculate the prediction and error\n",
    "                prediction = self.predict(input1, input2)\n",
    "                error = target - prediction\n",
    "\n",
    "                # update the weights if there is an error\n",
    "                if error:\n",
    "                    errors_this_epoch += 1\n",
    "                    self.bias_weight += error * 1.0 * self.learning_rate # bias input is always +1\n",
    "                    self.weight1 += error * input1 * self.learning_rate\n",
    "                    self.weight2 += error * input2 * self.learning_rate  \n",
    " \n",
    "                self.print_message(input1, input2, target, prediction)\n",
    "\n",
    "            # print message and decide whether to continue\n",
    "            if(errors_this_epoch > 0):\n",
    "                print(f\"Overall in epoch {epoch} there were {errors_this_epoch} errors\\n\")\n",
    "            else:\n",
    "                print(f\"Perceptron solved the learning problem in {epoch} epochs\")\n",
    "                break\n",
    "\n",
    "\n",
    "    def predict(self, input1:int, input2:int) -> int:\n",
    "\n",
    "        # step 1 multiply each input by its weight and sum them\n",
    "        summed_input = input1*self.weight1 + input2*self.weight2 + 1.0*self.bias_weight\n",
    "        \n",
    "        # step 2 compare sum to threshold (0) to decide output\n",
    "        if summed_input > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "    def print_message(self, input1:int, input2:int, target:int, prediction:int):\n",
    "        error = target - prediction\n",
    "        message = (f\"Input1: {input1} Input 2: {input2}, \"\n",
    "                            f\"target label {target}, \"\n",
    "                            f\"predicted label {prediction} \"\n",
    "                f\"so error = {error:2d}. \")\n",
    "        if not error:\n",
    "            message += \"So no update\"\n",
    "        else:\n",
    "            message += (f\"After updates: w1 {self.weight1:.4f}, \"\n",
    "                        f\"w2 {self.weight2:.4f} \"\n",
    "                        f\"biasweight {self.bias_weight:.4f}\")\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 3: Train the perceptron\n",
    "\n",
    "As it trains, in each epoch you will be told when it makes a prediction error, and what the updated weights are you should see output for the current inputs and target outputs,\n",
    "training step, epoch and total error for that epoch.  \n",
    "**Run the next cell** to **create** classifier model  and **fit** (train) it on the AND data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the data and target outputs to use (AND, OR, XOR)\n",
    "target_outputs = target_outputs_AND\n",
    "\n",
    "# Create a perceptron and fit it to the data\n",
    "lr = 0.1\n",
    "my_perceptron = two_input_perceptron(learning_rate=lr)\n",
    "\n",
    "my_perceptron.fit(inputs, target_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Test your understanding\n",
    "**Run the cell below and answer the questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import workbook7_mcq\n",
    "display(workbook7_mcq.Q1)\n",
    "\n",
    "display(workbook7_mcq.Q2)\n",
    "\n",
    "display(workbook7_mcq.Q3)\n",
    "\n",
    "display(workbook7_mcq.Q4)\n",
    "\n",
    "display(workbook7_mcq.Q5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "<div style=\"background:black;width:100%;height:10px\"></div>\n",
    "\n",
    "# Part 2: Perceptrons learn Straight Decision Boundaries!\n",
    "<img src=\"figures/straightLine.png\" width=\"300\" style=\"float:right\">\n",
    "\n",
    "To give you an intuition for what the Perceptron is doing, consider the equation for a straight line:\n",
    "\n",
    "$y = mx + c$\n",
    "\n",
    "*a*and *c* are coefficients just like the learned weights and bias in the Perceptron.\n",
    "\n",
    "Now lets think about when the perceptron's behaviour (output) changes as the inputs vary.\n",
    "- We know that the output depends on whether the sum of the weighted inputs is greater than zero (output 1) or not (output 0).\n",
    "- But if we are using the perceptron to make predictions,   \n",
    "  then saying that *the behaviour changes when ...*    \n",
    "  is the same as saying: *the decision boundary is when ...*\n",
    "  \n",
    "- In other words **the decision boundary for a perceptron** is when $y =0$ where      \n",
    "$y = input1 \\times weight1 \\;\\; + input2 \\times weight2\\;\\; + \\;\\;bias\\_weight$  \n",
    "\n",
    "\n",
    "Setting $y = 0$ and re-arranging the equation in terms of the two inputs gives:\n",
    "\n",
    "$input2 = - \\frac{weight1}{weight2} \\times input1 -  \\frac{bias\\_weight}{weight2}$\n",
    "\n",
    "Which is the same form as the equation for a straight line where:\n",
    "- the ratio of the bias weight to weight2 defines the intercept  \n",
    "  i.e., the critical value of input2 when input1 = 0\n",
    "- the ratio of weights 1 and 2 defines the slope/gradient of the line (a)  \n",
    "  i.e., how much the critical value of input2 changes each time input1 changes by +1 \n",
    "\n",
    "So for any given value of input1, we can use this equation to tell us the critical value of input2\n",
    "- above that the output is 1,  below that, the output is 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:black;width:100%;height:5px\"></div><br>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"color:black\"><h2>Activity 2: Interactively changing weights to mimic automatic learning</h2>\n",
    "Run the code cell below to create an interactive widget that allows you to manually adjust the weights, and see how the decision boundary moves.<br>\n",
    "\n",
    "<b>Note:</b>You don't need to understand the python in the first cell- it sets up the sliders, the radio buttons and the plot widget.\n",
    "\n",
    "<b>Note:</b> This widget will not work in VScode, you need to run it in Jupyterlab (in browser).\n",
    "\n",
    "<ul>\n",
    "    <li> When you click to show different functions, the colour (target) of the dots at (0,0),(0,1),(1,0) and (1,1) change.</li>\n",
    "    <li> The sliders let you manually control the values of the perceptron weights.</li>\n",
    "    <li> The red line shows the decision boundary calculated from the weight values.</li>\n",
    "    <li> When the weights are correct (i.e. the perceptron will correctly predict) that function:<br>\n",
    "            red dots should be 0 (below the line), and green dots should be 1 (above the line).</li>\n",
    "</ul>\n",
    "\n",
    "You do not need to remember the equation for the calculating the decision boundary. But you should try and understand how this decision boundary relates to the Perceptrons output (and why it can only be straight).\n",
    "<ol>\n",
    "    <li>Try different functions, and see if you can manually tweak the slider values so that the red line separates the red and green dots.</li>\n",
    "    <li>You might find it helpful to go around the four points (00, 10, 01, 11) in turn, and looking at whether they are on the wrong side of the line.</li>\n",
    "    <li>If so, moving the appropriate sliders a little by hand, to mimic what the update mechanism does automatically.</li>\n",
    "    <li> Finally, answer the questions in the second cell.</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "**Run the cell below** and **experiment** to observe and understand the behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import matplotlib.pyplot as plt\n",
    "import workbook7_mcq\n",
    "%matplotlib inline\n",
    "\n",
    "# Create sliders for the weights and bias\n",
    "weight1 = widgets.FloatSlider(value=-0.5, min=-1, max=1)\n",
    "weight2 = widgets.FloatSlider(value=0.5, min=-1, max=1)\n",
    "biasweight = widgets.FloatSlider(value=-0.5, min=-1, max=1)\n",
    "funcToModel = widgets.RadioButtons(options=['OR','AND','XOR'])\n",
    "# Create the interactive plot\n",
    "output = interact(workbook7_mcq.showPerceptron, w1=weight1, w2=weight2, bias=biasweight, func=funcToModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(workbook7_mcq.Q6)\n",
    "display(workbook7_mcq.Q7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div style=\"background:black;width:100%;height:10px\"></div>\n",
    "\n",
    "# Part 3: Learning data with real-value (continuous) features\n",
    "\n",
    "Truth table data and logical functions are a good way to learn the Perceptron algorithm but the data isn't very realistic.\n",
    "\n",
    "Most problems are much more complex and cannot be represented with binary data or solved with only 4 training examples.  \n",
    "We were also only training for one **step** (one input example) or one **epoch** (all input examples) at a time, so that we\n",
    "could see what the algorithm was doing.\n",
    "\n",
    "In supervised learning, generally we want to train for a fixed number of epochs, or until there is no improvement in\n",
    "the error on the training data.   \n",
    "Once training is finished we apply the model (trained weights) to some test data and\n",
    "measure its performance.   \n",
    "This gives us an indication of how well it would perform on new data it has not 'seen' before.\n",
    "\n",
    "Next we will train and then test a Perceptron on a larger, real numbered dataset so that we can see the process of \n",
    "applying machine learning in practice. \n",
    "- We'll use the Iris one, as you should be familiar with it by now.\n",
    "\n",
    "- **The difference** is that perceptrons only handle two classes \n",
    "  - so to start with we will just make a binary setosa/not-setosa classifier.\n",
    "\n",
    "As before, we will first import some python modules and then the load the iris data\n",
    "- The other call in the first cell splits the data created into train and test sets. \n",
    "\n",
    "- you **don't** have to understand how the visualisation code works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the Iris data\n",
    "\n",
    "**Run the cell below** to load the data, convert it into a 2 class (binary problem) and split into training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the data\n",
    "irisX, irisy = load_iris(return_X_y=True)\n",
    "\n",
    "# Convert into a binary classification problem\n",
    "flower_class = 0  # setosa (could be 1 for versicolor, or 2 for virginica)\n",
    "\n",
    "# Using numpy *where* function - the equivalent of an if, but applies to a whole array\n",
    "class_labels = np.where(irisy==flower_class, 1, 0)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(irisX, class_labels, test_size=0.33, stratify=irisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implementing n input perceptron\n",
    "\n",
    "This is the same algorithm as before, the only difference is it will work with variable (n) numbers of input features instead of 'hard coding' the number of weights, because we need one weight per input.\n",
    "\n",
    "The class below extends the two-input perceptron class from above, so that it:\n",
    "\n",
    "1. **Is more generic** - and  can cope with any number of inputs.   \n",
    "   - To achieve that we move the weight initialisation from the constructor to the fit() function.\n",
    "   - Use a numpy array of weights rather than holding them in a fixed set of variables.  \n",
    "   - This lets it  deal with data with any number of features by querying the data's *shape* attribute.<br><br>\n",
    "\n",
    "3. Has a **fit()** method that uses a vector of weights rather than making assumptions about data shape.\n",
    "   - This also means it will match the sklearn models way of doing things.\n",
    "   - Training will stop:\n",
    "     - when  the whole training set is presented (one epoch) with no prediction errors, or  \n",
    "     - after a fixed number of epochs have been run - because we can't assume 100% accuracy is achievable!<br><br>\n",
    "\n",
    "3. Implements a **predict()** method that  takes a set of items to predict as a parameter.\n",
    "   - This method can be used  to estimate the performance of our model on a held back test set.\n",
    "   - It just loops over the cases calling a method predict_one().<br><br>\n",
    "\n",
    "4. Implements a method **predict_one()** that presents the  set of feature values corresponding to one new item/example to the network and returns the network's output value.\n",
    "\n",
    "**Run the cell below to define this class.** Ask your peers or a tutor if you do not understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class n_input_perceptron:\n",
    "    def  __init__(self, learning_rate:float=0.1, debug=True):\n",
    "        # The only weight we set in the constructor is a random initial  bias weight\n",
    "        self.bias_weight = random()\n",
    "        self.learning_rate = learning_rate \n",
    "        self.debug = debug\n",
    "        \n",
    "    def fit(self, data:np.ndarray, labels:np.array, max_epochs:int=50):\n",
    "        \"\"\" fits the perceptron weights to the supplied data\"\"\"\n",
    "        \n",
    "        # Find the number of input features in the data\n",
    "        self.num_inputs = data.shape[1]\n",
    "        # Then create that many weights and randomise them\n",
    "        self.weights = np.random.rand(self.num_inputs)\n",
    "       \n",
    "        # loop for a number of epochs if needed\n",
    "        for epoch in range(max_epochs):\n",
    "            errors_this_epoch = 0\n",
    "\n",
    "            # loop through each training example in turn\n",
    "            for example in range(len(data)):\n",
    "\n",
    "                target = labels[example]\n",
    "\n",
    "                # calculate the prediction and error\n",
    "                prediction = self.predict_one(data[example])\n",
    "                error = target - prediction\n",
    "\n",
    "                # update the weights if there is an error\n",
    "                if error:\n",
    "                    errors_this_epoch += 1\n",
    "\n",
    "                    self.bias_weight += error * 1.0   *self.learning_rate  # bias input is always +1\n",
    "                    for position in range(self.num_inputs):\n",
    "                        self.weights[position] += error * data[example][position] * self.learning_rate\n",
    " \n",
    "            # print message and decide whether to continue\n",
    "            if(errors_this_epoch > 0):\n",
    "                print(f\"Epoch {epoch+1} there were {errors_this_epoch} errors\\n\")\n",
    "            else:\n",
    "                print(f\"Perceptron solved the learning problem in {epoch+1} epochs\")\n",
    "                break\n",
    "\n",
    "        # we've finished!\n",
    "        self.is_fitted_=True\n",
    "\n",
    "    # this predict method is changed to take an array of inputs instead of just two\n",
    "    def predict_one(self, input_values) -> int:\n",
    "\n",
    "        summed_input =  self.bias_weight  * 1.0  # since bias always has the input value 1.0\n",
    "        for i in range(self.num_inputs):\n",
    "            summed_input += input_values[i] * self.weights[i]\n",
    "        \n",
    "        # Threshold the sum to get the output prediction\n",
    "        return 1 if summed_input > 0 else 0\n",
    "        \n",
    "\n",
    "    # The new predict() method will now accept a set of examples to make predictions for\n",
    "    # it just runs a loop repeatedly calling a function to predict for one case\n",
    "    def predict(self, data):\n",
    "\n",
    "        # ask the data how many rows it has\n",
    "        num_to_predict = data.shape[0]\n",
    "\n",
    "        predictions = []\n",
    "        for new_case in range(num_to_predict):\n",
    "            predictions.append (self.predict_one(data[new_case]) )\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:black;width:100%;height:5px\"></div><br>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"color:black\"><h2>Activity 3: Learning from  examples with  continuous features</h2>\n",
    "The aim of this activity is to illustrate how Perceptrons can be applied to a larger, more realistic, dataset with real numbered features.\n",
    "The following cell trains a perceptron on the binary version of Iris data:\n",
    "<ol>\n",
    "    <li>Try changing the <code>learning_rate</code> parameter, which controls how large the change in weights is, and see how that effects learning.</li>\n",
    "    <li>Try changing the <code>max_epochs</code> parameter, which controls how many iterations of model adaptation happen.</li>\n",
    "    <li>Explore what effect these have on how well the perceptron learns the training data. Remember to run the second cell a few times since the perceptron starts with a random model (set of weights).</li>\n",
    "</ol>\n",
    "\n",
    "Then run the following cell to see how well it performs on the 'unseen' test data.<br>\n",
    "<b>Note:</b>Now we just call <code>predict()</code> but we dont update the weights.\n",
    "</div>\n",
    "\n",
    "**Run the cells below** to **create** an instance of this class, **fit** it  and then **evaluate** on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "lr = 0.05\n",
    "epochs = 50\n",
    "\n",
    "# Create a perceptron and fit it to the data\n",
    "my_perceptron = n_input_perceptron(learning_rate=0.05)\n",
    "my_perceptron.fit(train_X, train_y, max_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = my_perceptron.predict(test_X)\n",
    "\n",
    "# Compare those to the true values to see how well the perceptron did\n",
    "correct = 0\n",
    "for example in range(test_X.shape[0]):\n",
    "    if (predictions[example] == test_y[example]) :\n",
    "        correct += 1\n",
    "incorrect = correct - test_X.shape[0]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * (test_y == predictions).sum() / test_y.shape[0]\n",
    "print (f\"On the unseen test data the perceptron made {correct} correct predictions and {incorrect} errors so the accuracy is {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:black;width:100%;height:5px\"></div><br>\n",
    "\n",
    "\n",
    "## Learning from data with more  features and classes\n",
    "<img src=\"figures/cascading.png\" style=\"float:right\">\n",
    "\n",
    "Since perceptrons can only make two-way distinctions for multi-class data (like Iris) we have a choice of options:\n",
    "\n",
    "1. (simplest) we create three classifiers - one to recognise each class. \n",
    "    - This requires a way of specifying how to combine their votes,\n",
    "    - and what to do if all three say \"not in class\".\n",
    "\n",
    "2. (slightly more complex) use a cascade approach (shown in image)\n",
    "    - first train a network to predict if a training item is setosa or not.\n",
    "    - then use the training items that are predicted 'not-setosa' to train a second perceptron that predicts versicolor-or virginica.\n",
    "\n",
    "In the next few cells we show how to create a cascading classifier.\n",
    "\n",
    "**Run the cell below** to load the data set and split it into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris data\n",
    "iris_data = load_iris(return_X_y=False)\n",
    "# Extract the data and labels, feature names, and label names\n",
    "irisX = iris_data.data\n",
    "irisy = iris_data.target\n",
    "feature_names = iris_data.feature_names\n",
    "label_names = iris_data.target_names\n",
    "\n",
    "print(f\"Iris has {irisX.shape[0]} samples and {irisX.shape[1]} features: {feature_names}\")\n",
    "print(f\"Iris has 3 classes: {label_names}\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_X, test_X, train_y, test_y = train_test_split(irisX, irisy, test_size=0.33, stratify=irisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to set up  version of the labels which just treat the data as setosa (0) or not (1), by setting the values 2 (virginica) to 1 and the same thing to make some versicolor labels.\n",
    "**Run the cell below** to make sets of labels for the different 1-vs-all sub-problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make zeros arrays of right size then loop through putting in 1s for the appropriate classes\n",
    "versicolor_train_y = np.zeros(len(train_y), dtype=int)\n",
    "setosa_train_y = np.zeros(len(train_y), dtype=int)\n",
    "for i in range(len(train_y)):\n",
    "    if train_y[i] == 0:\n",
    "        setosa_train_y[i] = 1\n",
    "    if train_y[i] == 1:\n",
    "        versicolor_train_y[i] = 1\n",
    "\n",
    "setosa_test_y = np.zeros(len(test_y), dtype=int)\n",
    "versicolor_test_y = np.zeros(len(test_y), dtype=int)\n",
    "for i in range(len(test_y)):\n",
    "    if test_y[i] == 0:\n",
    "        setosa_test_y[i] = 1\n",
    "    if test_y[i] == 1:\n",
    "        versicolor_test_y[i] = 1\n",
    "\n",
    "\n",
    "print(f\"First 25 original   labels {test_y[:25]}\")\n",
    "print(f\"First 25 setosa     labels {setosa_test_y[:25]}\")\n",
    "print(f\"First 25 versicolor labels {versicolor_test_y[:25]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Train a perceptron for the setosa : not setosa task\n",
    "**Run the cell below** to\n",
    "- train a perceptron to do the *setosa*:*not-setosa* recognition task.  \n",
    "-  make predictions  and get the id's of the training items classified as *not-setosa*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training the first stage classifier - setosa:not-setosa\")\n",
    "setosa_classifier =  n_input_perceptron(learning_rate=0.05, debug=True)\n",
    "setosa_classifier.fit(train_X, labels=setosa_train_y, max_epochs=20)\n",
    "\n",
    "setosa_predictions = setosa_classifier.predict(train_X)\n",
    "\n",
    "# Count how many we predicted as setosa like this\n",
    "num_setosa_predictions = np.array(setosa_predictions).sum()\n",
    "num_not_setosa_predictions = train_X.shape[0] - num_setosa_predictions\n",
    "\n",
    "print(f\"The first stage made {num_setosa_predictions}:{num_not_setosa_predictions} setosa:not_setosa predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Collect subsets of training data not predicted to be setosa\n",
    "\n",
    "In other words, split the original data and only keep examples/labels for items *not* classified as setosa.   \n",
    "**Run the cell below** to create the subset of data used to train  the **second stage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We found the number of items being passed through in the last cell\n",
    "# use this to allocate new arrays\n",
    "not_setosa_x = np.empty((num_not_setosa_predictions, 4))\n",
    "not_setosa_y = np.empty(num_not_setosa_predictions)\n",
    "\n",
    "# Loop through making copies of every training item not predicted to be setosa\n",
    "# but this time taking the versicolor labels as our targets\n",
    "new_index = 0\n",
    "for i in range(train_X.shape[0]):\n",
    "    if (setosa_predictions[i] == 0):\n",
    "        not_setosa_x[new_index] = train_X[i]\n",
    "        not_setosa_y[new_index] = versicolor_train_y[i]\n",
    "        new_index += 1\n",
    "        \n",
    "# Check we got them all\n",
    "assert new_index == num_not_setosa_predictions\n",
    "\n",
    "print (f\"Shape of data and labels (not setosa) being passed to second classifier are {not_setosa_x.shape} and {len(not_setosa_y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Training a perceptron for the versicolor : virginica task\n",
    "\n",
    "**You may want to run the cell a few times** to get a good result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Training the second stage classifier - versicolor:viginica\")\n",
    "versicolor_classifier =  n_input_perceptron(learning_rate=0.01, debug=True)\n",
    "versicolor_classifier.fit(not_setosa_x, labels=not_setosa_y, max_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Put together our two-stage classifier\n",
    "**Run the cell below to define the new class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Put together our two-stage classifier\n",
    "def CascadePredict(new_item, setosa_classifier, versicolor_classifier):\n",
    "    \n",
    "    prediction = -1\n",
    "\n",
    "    # First stage prediction\n",
    "    first_stage_prediction = setosa_classifier.predict_one(new_item)\n",
    "\n",
    "    if first_stage_prediction == 1:  # setosa\n",
    "        prediction = 0\n",
    "    else:\n",
    "        # Second stage prediction\n",
    "        second_stage_prediction = versicolor_classifier.predict_one(new_item)\n",
    "\n",
    "        if second_stage_prediction == 1:\n",
    "            prediction = 1  # versicolor\n",
    "        else:\n",
    "            prediction = 2  # virginica\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluating our 2-stage classifier and visualising the confusion matrix\n",
    "\n",
    "**Run the cell below** it should show the results for the new classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the cascade classifier on the test data\n",
    "two_stage_predictions = []\n",
    "correct = 0\n",
    "for i in range (test_X.shape[0]):\n",
    "    pred = CascadePredict(test_X[i], setosa_classifier, versicolor_classifier)\n",
    "    two_stage_predictions.append(pred)\n",
    "\n",
    "    if pred == test_y[i]:\n",
    "        correct += 1\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = 100 * (test_y == two_stage_predictions).sum() / test_y.shape[0]\n",
    "print(f\"\\nOverall Accuracy = {accuracy:.2f} %\")\n",
    "print(f\"Final outcome: {correct} out of {test_X.shape[0]} correct test predictions from Cascaded classifier\")\n",
    "\n",
    "\n",
    "\n",
    "_= ConfusionMatrixDisplay.from_predictions(test_y, two_stage_predictions, display_labels=label_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"color:black\"><b>Save and close Jupyter:</b>\n",
    "    <ol>\n",
    "        <li>Use the jupyterlab functions to download your work (ask your tutor if you need help with this) and save it somewhere sensible so you can find it easily.</li>\n",
    "        <li>Shutdown the notebook when you have finished with this tutorial (menu->file->close and shutdown notebook)</li>\n",
    "    </ol>\n",
    "</div"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
